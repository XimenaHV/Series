---
title: "Tarea SARIMA"
author: "Raúl,Ximena,Jhonatan"
format: 
 html:
    embed-resources: true
    toc: true
---

```{r}
#| message: false
library(tidyverse)
library(fpp3)
library(patchwork)
library(plotly)
library(forecast)
```

## Visualización

```{r}
h02 <- PBS %>%
  filter(ATC2 == "H02") %>%
  summarise(Cost = sum(Cost)/1e6)

h02 %>%
  mutate(Cost) %>%
  gather() %>%
  ggplot(aes(x = Month, y = value)) +
  geom_line() +
  facet_grid(key ~ ., scales = "free_y") +
  xlab("Year") + ylab("") +
  ggtitle("Cortecosteroid drug scripts (H02)")
```

## Separar los datos en train and test

```{r}
h02_train <- h02 |> 
  filter_index(. ~ "2006 Q1")

p <- h02_train |> 
  autoplot(Cost) +
  labs(
    title = "H02 train",
    y = "Cost"
  )

ggplotly(p, dynamicTicks = TRUE) |> 
  rangeslider()
```

## Revisar si la serie es estacionaria

Al observar la serie original, vemos que no es estacionaria por la varianza por lo que realizo una transformación logaritmica

```{r}
h02 %>%
  mutate(log(Cost)) %>%
  gather() %>%
  ggplot(aes(x = Month, y = value)) +
  geom_line() +
  facet_grid(key ~ ., scales = "free_y") +
  xlab("Year") + ylab("") +
  ggtitle("Cortecosteroid drug scripts (H02)")
```

Se ve mejor la serie en logaritmos, para estabilizar el ligero incremento en la varianza. La serie presenta una fuerte estacionalidad mensual y obviamente es no estacionaria. Tomaremos diferencias estacionales:

# Aplicar diferenciación

```{r}
h02 %>% gg_tsdisplay(difference(log(Cost), 12), plot_type='partial', lag_max = 48)

h02 %>% gg_tsdisplay(log(Cost) %>% difference(12) %>% difference(), plot_type='partial', lag_max = 48)
```

De estas gráficas no queda claro si se requiere una diferenciación adicional o no. Seguimos, por lo pronto, solo con las diferencias estacionales.

En la gráfica de la PACF vemos que se presentan picos en los rezagos 12 y 24, pero ninguno en la ACF. Esto sugiere un componente **AR(2) estacional**. Tomando los rezagos no estacionales, vemos picos en los primeros tres, lo que indicaría un componente **AR(3) no estacional**. El patrón que se observa en la ACF no indica ningún modelo sencillo. Este modelo propuesto sería un $\operatorname{ARIMA}(3,0,0)(2,1,0)_{12}$.

Este caso requiere de realizar varias pruebas para intentar identificar el mejor modelo.

En ocasiones, ningún modelo logra cumplir todas las pruebas.

**NOTA:** Para comparar el desempeño entre modelos a través de los criterios de información ($AIC_c$), es necesario que **el orden de diferenciación sea el mismo en todos los modelos**. Sin embargo, cuando se compara a los modelos utilizando un conjunto de datos de prueba (a través de las métricas de error), es indiferente cómo se produjeron los pronósticos; las comparaciones siempre son válidas.

# Posibles modelos

```{r}
h02_fit <- h02_train |> 
  model(
    sarima_300_210 = ARIMA(log(Cost) ~ pdq(3,0,0) + PDQ(2,1,0)),
    sarima_111_212 = ARIMA(log(Cost) ~ pdq(1,1,1) + PDQ(2,1,2)),
    sarima_110_212 = ARIMA(log(Cost) ~ pdq(1,1,0) + PDQ(2,1,2)),
    sarima_110_213 = ARIMA(log(Cost) ~ pdq(1,1,0) + PDQ(2,1,3)),
  )

h02_fit
```

# Ajustar sobre datos de entrenamiento

```{r}
h02_fit |> 
  select(sarima_300_210) |> 
  report()

h02_fit |> 
  select(sarima_111_212) |> 
  report()

h02_fit |> 
  select(sarima_110_212) |> 
  report()

h02_fit |> 
  select(sarima_110_213) |> 
  report()

```

```{r}
h02_fit |> 
  glance() |> 
  arrange(AICc)
```

De acuerdo con el AICc, el mejor modelo sería el "ARIMA(1,1,1)(2,1,2)"

# Diagnóstico de residuos

```{r}
h02_fit |> 
  select(sarima_300_210) |> 
  gg_tsresiduals()

h02_fit |> 
  select(sarima_111_212) |> 
  gg_tsresiduals()

h02_fit |> 
  select(sarima_110_212) |> 
  gg_tsresiduals()

h02_fit |> 
  select(sarima_110_213) |> 
  gg_tsresiduals()
```

```{r}
h02_fit |> 
  augment() |> 
  features(.innov, ljung_box, lag = 22) |> 
  mutate(residuos_autocorrelacionados = if_else(lb_pvalue >=0.05, "No autocorrelación", "Autocorrelacionados"))
```

Ya son ruido blanco por lo que se puede continuar.

# Errores

Realizando pruebas para identificar los errores en nuestro modelo, obtuvimos los siguientes resultados:

ARIMA(3,0,0)(2,1,0) = 1.1 MASE ARIMA(1,1,1)(2,1,2) = 0.791 MASE ARIMA(1,1,0)(2,1,2)= 0.785 MASE ARIMA(1,1,0)(2,1,3) = 0.748 MASE

Podemos observar que el modelo ARIMA(1,1,0)(2,1,3) presenta el menor error, por lo tanto, utilizaremos este modelo para realizar el pronóstico

# Pronostico ARIMA(1,1,0)(2,1,3)

```{r}
h02 %>% 
  model(`ARIMA(1,1,0)(2,1,3)` = ARIMA(log(Cost) ~ pdq(1,1,0) +
                                        PDQ(2,1,3))) %>% 
  forecast(h = 30) %>% autoplot(h02) +
  ggtitle("Pronóstico generado con un modelo ARIMA(1,1,0)(2,1,3)")
```
